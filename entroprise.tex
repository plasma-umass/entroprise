\documentclass[11pt]{article}

\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{multicol}
\usepackage{graphicx}
\usepackage{blindtext}
\usepackage[legalpaper, margin=1in]{geometry}
\usepackage{mathtools}

\DeclarePairedDelimiter\abs{\lvert}{\rvert}%

\setlength{\columnsep}{1cm}

\author{
    Michael Steranka\\
    Department of Computer Science\\
    University of Massachusetts Amherst\\
    Amherst, MA, USA\\
    \texttt{msteranka@umass.edu}
    \and
    Emery D. Berger\\
    Department of Computer Science\\
    University of Massachusetts Amherst\\
    Amherst, MA, USA\\
    \texttt{emery@cs.umass.edu}
}
\title{Entroprise: Quantifying Object Reuse Security in Modern Allocators}
\date{}

\begin{document}

\maketitle

\begin{multicols*}{2}

\section*{Abstract}

\noindent Memory-related exploitations are a growing concern among security professionals.
As the prevalence of such exploitations increases, researchers have attempted to implement
secure memory allocators to mitigate their effects.
However, few means exist for quantitatively measuring allocator security.
In this paper, we present Entroprise: a utility for measuring an allocator's ability to minimize the effectiveness of use-after-free attacks.
Entroprise utilizes two proxies for measuring use-after-free security: entropy and randomness, and for several secure and insecure allocators, we provide their entropy and randomness in the worst-case scenario as well as when run alongside practical applications.
Additionally, we also provide security analyses for each allocator that cover security concerns beyond object reuse.

\section{Introduction}

To provide reasonable security without significantly compromising performance, many secure allocators will randomize object reuse to prevent attackers from predicting which objects to corrupt.
However, no utilities that we are aware of exist to measure the security of a particular allocator's object reuse policy. 
Regardless of an allocator's specific reuse policy, all allocators that use randomization should have a non-deterministic reuse mechanism.
We break down nondeterminism into two categories for reuse: entropy and randomness.
If an allocator exhibits low reuse entropy, then it is not secure.
If an allocator exhibits high entropy but low randomness, then it is not secure.
If an allocator exhibits both high entropy and high randomness, then it has a secure reuse policy.
We now diverge towards a discussion of how we define and measure entropy as well as randomness.

\subsection{Entropy}

\noindent Vaguely speaking, entropy is the amount of uncertainty associated with a random variable.
We measure entropy with the following formula:

\[ H(X) = -\sum_{i=1}^{n} P(x_i)\log_2P(x_i) \]

\noindent where \( X \) is a discrete random variable, and each \( x_i \) is an object.
However, the entropy depends on the number of allocations, which can vary across applications.
Therefore, we concern ourselves more with an allocator's normalized entropy:

\[ N(X) = \frac{H(X)}{\log_2n} \]

\noindent where \( n \) is the number allocations.

However, entropy itself remains insufficient for quantifying object reuse security.
For example, an allocator could delay object reuse by reusing objects in a FIFO order.
Clearly, object reuse would be completely deterministic, but the allocator would exhibit high entropy because an object will only be used again once all other objects in the free list have been exhausted.
Therefore, we require another proxy for measuring reuse security.

\subsection{Randomness}

\noindent In addition to measuring entropy, we also measure randomness.
We measure randomness by performing a series of Wald-Wolfowitz runs tests as well as a Kolmogorov-Smirnov test.

Given a set of random numbers, a runs test proceeds as follows:
We calculate the median of the set of random numbers.
For every value greater than the median, we assign it a positive value.
For every value less than the median, we assign it a negative value. 
We exclude all values that are equal to the median.
We then divide the sequence into runs, a series of consecutive positive or negative values.
Then, we count the number of runs, the number of positive values, and the number of negative values.
We then calculate the expected number of runs and expected variance as follows:

\[ \bar{R} = \frac{2n_1n_2}{n_1 + n_2} + 1 \]

\[ s^2_R = \frac{2n_1n_2(2n_1n_2-n_1-n_2)}{(n_1 + n_2)^2(n_1 + n_2 - 1)}\]

\noindent where \( n_1 \) and \( n_2 \) are the number of positive and negative values, respectively.
We then calculate our test statistic as follows:

\[ Z = \frac{R - \bar{R}}{s_R} \]

\noindent where \( R \) is the calculated number of runs.
Finally, we obtain the corresponding p-value by performing a two-tailed hypothesis and looking up the standard normal table \textbf{TODO [INSERT REFERENCE]}.

After performing 100 runs test, we should expect the 100 p-values to approximate a uniform distribution. 
We test for this property by performing a Kolmogorov-Smirnov test. 
First, we sort the p-values, and then we find the largest distance between the p-values and the uniform distribution, designated \( D \).
We perform this test at the \(\alpha = \) \textbf{TODO} significance level, where \( D_\alpha = \) \textbf{TODO}.
Therefore, if \( 0.565 > D \), then the entire sequence is random. Otherwise, the sequence is not random.

In addition to performing statistical tests for determining randomness, we have also generated scatter plots, where the x-axis is the allocation time, the y-axis is the address, and each point represents an address returned by \textit{malloc} during the process' execution. 
Since every address is a multiple of eight, we divide each address by eight, and we also take the modulo of the address by 4096 to tighten the range further. 
We also perform random sampling from the sequence of addresses if the full sequence is too large to generate meaningful scatter plots.

\section{Entroprise}

\noindent Entroprise measures entropy and randomness on a per-thread basis. 
Originally, entropy and randomness were measured globally, but we found that measuring globally unfairly biases towards allocators that assign subheaps on a per-thread basis.

Initially, when measuring entropy and randomness, we attempted to use the function \textit{atexit} to print results upon process termination.
However, the function specified by \textit{atexit} would never be called.
In turn, we decided to print out all data every power of two allocation, but this implementation has the obvious disadvantage that a significant number of data would be forgone.
Therefore, in its current state, Entroprise forks a given file and overrides the standard allocator by specifying the process' LD\_PRELOAD variable to Entroprise's own \textit{malloc}, which calls the allocator's allocation routine.

Entroprise utilizes a HyperLogLog data structure for approximating entropy. 
Upon every call to \textit{malloc}, the address obtained from the allocator is added to the HyperLogLog.
When the forked process terminates, the entropy is calculated as \( \log_2c \), where \( c \) is the approximated cardinality in the HyperLogLog.
Although this measure of entropy is not exact, it provides a good approximation.

When measuring randomness, Entroprise appends every address to \textit{mmapped} region.
When the forked process terminates, the parent divides the addresses into 100 equally-sized sequences and performs a runs test on each sequence.
Then, the 100 p-values are used for the KS test. By default, Entroprise assumes a confidence level of \textbf{TODO} when determining whether the final p-value indicates a random sequence of addresses..

\section{Security Analyses}

\noindent Now we delve into a security analysis of each allocator studied for this paper. In total, eleven allocators were studied, five of which were designed with an emphasis on security.

Foremost, we have DieHarder.

We bring our attention to the Scudo Hardened Allocator developed by LLVM. 
Scudo supports randomized placement as well as randomized reuse.
Additionally, Scudo also delays object reuse before it randomly inserts them back onto their corresponding free lists.
To mitigate buffer overflows, Scudo inserts two byte dynamic canaries at the beginning of every object.
Finally, Scudo also has the ability to zero objects upon allocation and deallocation. \textbf{TODO [INSERT REFERENCE]}

\section{Analytical Results}

\noindent 

\section{Empirical Results}

\noindent Although the worst-case allocation pattern provides a lower bound on entropy and randomness, most practical applications do not exhibit an allocation pattern in exactly the same fashion.
Therefore, we also measure entropy and randomness in two benchmark suites, SPEC 2017 and PARSEC 3.0, as well as \textbf{TODO}.

\subsection{SPEC}

\subsection{PARSEC}

PARSEC contains thirteen applications for benchmarking, but we have found that only three of these benchmarks exhibit a reasonable amount of reuse and number of allocations for the results to be significant.
We measure reuse as the total number of allocations divided by the maximum number of live objects during the application's execution.
PARSEC's benchmarks are generally not security sensitive applications, and thus they remain a poor means of measuring allocator security.
Additionally, the benchmarks are not particularly allocation intensive, seeing as the largest number of allocations across all benchmarks is only about 50 million.

\section{Conclusion}

\noindent Clearly, there is plenty of room for further research into measuring and comparing allocator security, seeing as this paper only presents means of measuring reuse security. There are many aspects that contribute to security such as ability to mitigate the effects of buffer overflows.

\end{multicols*}

\end{document}
