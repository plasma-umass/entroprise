scudo/scudo_allocator.cpp:
    - void *allocate : line 301
    - By default, doesn't zero out objects' contents
    - Evidence that Scudo doesn't segregate metadata: line 368
    - Small object allocation: line 348

    if (PrimaryT::CanAllocate(AlignedSize, MinAlignment)) {
      BackendSize = AlignedSize;
      ClassId = SizeClassMap::ClassID(BackendSize);
      bool UnlockRequired;
      ScudoTSD *TSD = getTSDAndLock(&UnlockRequired);
      BackendPtr = Backend.allocatePrimary(&TSD->Cache, ClassId);
      if (UnlockRequired)
        TSD->unlock();
    } else {
      BackendSize = NeededSize;
      ClassId = 0;
      BackendPtr = Backend.allocateSecondary(BackendSize, Alignment);
    }

    - typeof(TSD->Cache) = AllocatorCacheT
    - TSD = Thread Specific Data
    - typeof(AllocatorCacheT) = CombinedAllocator::AllocatorCache
    - typeof(CombinedAllocator::AllocatorCache) = PrimaryAllocator::AllocatorCache
    *- TSD->Cache = SizeClassAllocator64<AP64>::AllocatorCache
    - typeof(Backend) = BackendT
    - typeof(BackendT) = CombinedAllocator
    *- Backend.allocatePrimary(&TSD->Cache, ClassId) = 
        CombinedAllocator.allocatePrimary(SIzeClassAllocator64<AP64>::AllocatorCache, ClassId) = 
        SizeClassAllocator64<AP64>::AllocatorCache->Allocate(SizeClassAllocator<AP64>, ClassId)
    
    typeof(SizeClassAllocator64<AP64>::AllocatorCache) = SizeClassAllocator64LocalCache<ThisT>


********************************************************************************

scudo/scudo_allocator_combined.h:
    - using AllocatorCache = typename PrimaryAllocator::AllocatorCache;
    - typeof(PrimaryT) = SizeClassAllocator64<AP64>
    - typeof(PrimaryAllocator) = PrimaryT

********************************************************************************

sanitizer_common/sanitizer_allocator_local_cache.h:
    - line 33:

      void *Allocate(SizeClassAllocator *allocator, uptr class_id) {
        CHECK_NE(class_id, 0UL);
        CHECK_LT(class_id, kNumClasses);
        PerClass *c = &per_class_[class_id];
        if (UNLIKELY(c->count == 0)) {
          if (UNLIKELY(!Refill(c, allocator, class_id)))
            return nullptr;
          DCHECK_GT(c->count, 0);
        }
        CompactPtrT chunk = c->chunks[--c->count];
        stats_.Add(AllocatorStatAllocated, c->class_size);
        return reinterpret_cast<void *>(allocator->CompactPtrToPointer(
            allocator->GetRegionBeginBySizeClass(class_id), chunk));
      }

    - PerClass definition: line 77
    - typeof(CompactPtrT) = Allocator::CompactPtrT: line 75
    - CompactPtrT just represents a 4 byte integer relative to the beginning of a region instead of storing the entire 8 byte address
    - So allocations just entail pulling an address out of an array in order
    - They must be randomized during initialization

    - line 48:

    void Deallocate(SizeClassAllocator *allocator, uptr class_id, void *p) {
      CHECK_NE(class_id, 0UL);
      CHECK_LT(class_id, kNumClasses);
      // If the first allocator call on a new thread is a deallocation, then
      // max_count will be zero, leading to check failure.
      PerClass *c = &per_class_[class_id];
      InitCache(c);
      if (UNLIKELY(c->count == c->max_count))
        Drain(c, allocator, class_id, c->max_count / 2);
      CompactPtrT chunk = allocator->PointerToCompactPtr(
          allocator->GetRegionBeginBySizeClass(class_id),
          reinterpret_cast<uptr>(p));
      c->chunks[c->count++] = chunk;
      stats_.Sub(AllocatorStatAllocated, c->class_size);
    }

********************************************************************************

    - Therefore, chunks are reused in the same order within each size class in sanitizer_common
    - Allocator::deallocate() always calls Allocator::quarantineOrDeallocateChunk()
    - Chunks are only ever immediately deallocated instead of quarantining if their size exceeds the quarantine size threshold
    - Deallocation: getBackend().deallocatePrimary(&TSD->Cache, BackendPtr, Header->ClassId)
    - Quarantine: Quarantine.Put(getQuarantineCache(TSD), QuarantineCallback(&TSD->Cache), Ptr, EstimatedSize)

    - typeof(Quarantine) = QuarantineT
    - typeof(QuarantineT) = Quarantine<QuarantineCallback, void>

********************************************************************************

QUARANTINE
    - sanitizer_common/sanitizer_quarantine.h
    - Class definition: sanitizer_common/sanitizer_quarantine.h, line 76
    - If there's space remaining in the quarantine, then enqueue the address

    void Put(Cache *c, Callback cb, Node *ptr, uptr size) {
      uptr cache_size = GetCacheSize();
      if (cache_size) {
        c->Enqueue(cb, ptr, size);
      } else {
        // GetCacheSize() == 0 only when GetSize() == 0 (see Init).
        cb.Recycle(ptr);
      }
      // Check cache size anyway to accommodate for runtime cache_size change.
      if (c->Size() > cache_size)
        Drain(c, cb);
    }

    - typeof(Cache) = QuarantineCache<Callback>
    - Enqueue, line 221
    - Enqueue just appends a pointer to the end of a list
    - When are quarantined addresses returned to the backend? Are they only returned one at a time whenever Put() is called?

    - QuarantineCallBack::Recycle in scudo/scudo_allocator.cpp, line 181
    - Just changes chunk header stuff and calls getBackend().deallocatePrimary()
    - TODO: what is Drain()?, check in sanitizer_common/sanitizer_quarantine.h

********************************************************************************

SIZE CLASSES

free -> scudoDeallocate -> Allocator::deallocate -> CombinedAllocator::deallocatePrimary -> SizeClassAllocator64<AP64>::AllocatorCache->Deallocate -> SizeClassMap::kNumClasses
scudo_malloc.cpp -> scudo_allocator.cpp -> scudo_allocator_combined.h -> sanitizer_allocator_local_cache.h -> sanitizer_allocator_size_class_map.h

typedef SizeClassMap<3, 4, 8, 17, 8, 10> DenseSizeClassMap;
kMinSize = 16
kMidSize = 256
kMidClass = 16
S = 2

Scudo uses a DenseSizeClassMap (scudo_platform.h):
    - typedef SizeClassMap<3, 4, 8, 17, 8, 10> DenseSizeClassMap;
    - kNumClasses = 54 
    - I think that only 52 of them are actually used but whatever

c00 => s: 0 diff: +0 00% l 0 cached: 0 0; id 0
c01 => s: 16 diff: +16 00% l 4 cached: 256 4096; id 1
c02 => s: 32 diff: +16 100% l 5 cached: 256 8192; id 2
c03 => s: 48 diff: +16 50% l 5 cached: 256 12288; id 3
c04 => s: 64 diff: +16 33% l 6 cached: 256 16384; id 4
c05 => s: 80 diff: +16 25% l 6 cached: 256 20480; id 5
c06 => s: 96 diff: +16 20% l 6 cached: 256 24576; id 6
c07 => s: 112 diff: +16 16% l 6 cached: 256 28672; id 7

c08 => s: 128 diff: +16 14% l 7 cached: 256 32768; id 8
c09 => s: 144 diff: +16 12% l 7 cached: 256 36864; id 9
c10 => s: 160 diff: +16 11% l 7 cached: 256 40960; id 10
c11 => s: 176 diff: +16 10% l 7 cached: 256 45056; id 11
c12 => s: 192 diff: +16 09% l 7 cached: 256 49152; id 12
c13 => s: 208 diff: +16 08% l 7 cached: 256 53248; id 13
c14 => s: 224 diff: +16 07% l 7 cached: 256 57344; id 14
c15 => s: 240 diff: +16 07% l 7 cached: 256 61440; id 15

c16 => s: 256 diff: +16 06% l 8 cached: 256 65536; id 16
c17 => s: 320 diff: +64 25% l 8 cached: 204 65280; id 17
c18 => s: 384 diff: +64 20% l 8 cached: 170 65280; id 18
c19 => s: 448 diff: +64 16% l 8 cached: 146 65408; id 19

c20 => s: 512 diff: +64 14% l 9 cached: 128 65536; id 20
c21 => s: 640 diff: +128 25% l 9 cached: 102 65280; id 21
c22 => s: 768 diff: +128 20% l 9 cached: 85 65280; id 22
c23 => s: 896 diff: +128 16% l 9 cached: 73 65408; id 23

c24 => s: 1024 diff: +128 14% l 10 cached: 64 65536; id 24
c25 => s: 1280 diff: +256 25% l 10 cached: 51 65280; id 25
c26 => s: 1536 diff: +256 20% l 10 cached: 42 64512; id 26
c27 => s: 1792 diff: +256 16% l 10 cached: 36 64512; id 27

...

c48 => s: 65536 diff: +8192 14% l 16 cached: 1 65536; id 48
c49 => s: 81920 diff: +16384 25% l 16 cached: 1 81920; id 49
c50 => s: 98304 diff: +16384 20% l 16 cached: 1 98304; id 50
c51 => s: 114688 diff: +16384 16% l 16 cached: 1 114688; id 51

c52 => s: 131072 diff: +16384 14% l 17 cached: 1 131072; id 52

********************************************************************************

METADATA

deallocate, scudo_allocator.cpp, line 442
free -> scudoDeallocate (705) -> Allocator::deallocate (442) -> Chunk::loadHeader (142) -> getConstAtomicHeader (77)
scudo_malloc.cpp -> scudo_allocator.cpp

CONCLUSION: Metadata is NOT segregated from objects
